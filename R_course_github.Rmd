---
title: "R Project: Konza groundwater analysis; analysis of storage and surface flow intermittency"
output: github_document
author: Christopher Wheeler
---
## Prepare the R environment 
We will load any relevant packages and set the default for our code visibility in the final report.
```{r message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(zoo)
library(lubridate)
library(ggplot2)
library(plotly)
library(cowplot)
library(fs)
library(Rcpp)
library(sp)
library(raster)
library(rgdal)
library(rasterVis)
library(sf)
library(tidyverse)
library(dplyr)
library(dataRetrieval)
library(cowplot)
library(reshape2)
library(magrittr)
library(tidyr)
library(readxl)
library(janitor)
library(EnvStats)
library(fs)
```
## Konza Praire LTER Overview
Konza Prairie Biological Station (Konza) was designated as a Long-term Ecological Research Site (LTER) by NSF in 1981. In the 1990s, Dr. Gwen Macpherson coordinated the installation of multiple wells in the N04D watershed at Konza. All that historical groundwater data is accessible via the Konza Long-term Ecological Research Site webpage. Data include GWL measurements, as well as water quality data for many analytes This data I am going to analyze come from one of the many subwatersheds known as N04D. This watershed is grazed by bison for most of the year, and is subject to a controlled burn very four years. We will begin by looking at groundwater chemisty, then move to an examination of how well levels and storage are related to intermittency in surface flow. The subsurface geology at konza consists of a series of thinly interbedded limestones and mudstones, with water movement largely within secondary porosity of the limestone layers. Below is a map of the entire site for context.

## Site map: a. operations involving expanding, reorganizing, reshaping a data frame

```{r}
# Bring in `konza_boundary` shapefiles
konza_boundary <- st_read(
  "GIS002/GIS002.shp")

#Bring in `konza_streams` shapefile
konza_streams <- st_read(
  "GIS210/GIS210.shp")

ggplot() + 
  geom_sf(data = konza_boundary) + 
  geom_sf(data = konza_streams, color = "blue") + 
  theme_cowplot() +
  ggtitle("Konza Site Map") + 
  xlab("Longitude") + 
  ylab("Latitude") + 
  theme(plot.title = element_text(hjust = 0.5))
```

## Data Tidying and First Look: a. operations involving expanding, reorganizing, reshaping a dataframe

In this section, we will perform some basic data cleaning operations to get our data ready for further analysis
```{r}
# bring in and examine konza groundwater data set
kgw <- read_csv("kgw.csv", col_types = cols(WLDate = col_character()))
head(kgw)
names(kgw)
summary(kgw)
```
Below are some steps I used to tidy the raw data frame.
```{r warning = FALSE}
# from the summary, it appears that all of the actual chem data is in string format, so we need to convert to numeric
kgw[,11:ncol(kgw)]<- lapply(kgw[,11:ncol(kgw)], as.numeric)

#now convert date from character to proper format and clean up column names
kgw <- kgw %>% 
  mutate(date = lubridate::ymd(WLDate)) %>% 
  clean_names() %>% 
  dplyr::select(-wl_date)
```
Now that the data frame is cleaned up, I can start an exploratory analysis. As we learned in class, a good first pass at this is to simply create a cross plot of all the variables to check for any obvious correlations. When I first tried using plot with the whole data frame, I got an error saying that the margins were too large. I next tried to use a subsetted data frame with just the chemistry
```{r message = FALSE, warning = FALSE}

# subset original df to one with just chemical concentrations

all_na <- function(x) any(!is.na(x))

kgw_2 <- kgw %>% 
  select_if(all_na)

kgw_chem <- kgw_2 %>% 
  dplyr::select(-conduct, -date, -datacode, -rectype, -location, -trans, -plot, -geology, -recyear, -elevation, -sw_date)

names(kgw_chem)

kgw_chem_subset <- kgw_chem %>% 
  dplyr::select(na1, na2, ca1, ca2, nh4_n, no3_n, alkalinity, temp, mg1, cl, so4, k1)
```
## Cross Plot: d v. xy plot
```{r}
plot(kgw_chem_subset)
```

From this cross plot, a few correlations stand out to me a potentially significant, including the correlations between mg and ca. We will revisit this relationships later.

## Exploration of the chemistry of wells screened in different units: a. operations involving expanding, reorganizing, reshaping a data frame

Additionally, as a first pass I want to look at differences among wells screened in different geologic units. First I need to do some subsetting.
```{r}
kgw_2 <- kgw_2 %>% 
  mutate(geology = as_factor(geology))

kgw_geosub <- kgw_2[kgw_2$geology == 'AL' | kgw_2$geology == 'AL' | kgw_2$geology == 'Eis'   
                 | kgw_2$geology == 'Eis 1' | kgw_2$geology == 'Eis 2'  | kgw_2$geology == '1Mor'| kgw_2$geology == 'Mor', ]
```
## Boxplot: d iv. boxplot
```{r warning = FALSE}
ggplot(kgw_geosub, aes(x = factor(geology), y = no3_n, fill = geology)) + 
  geom_boxplot() + 
  theme_cowplot() + 
  xlab("Geologic Unit") + 
  theme(legend.position="none") + 
  ylab(bquote(NO[3]^" -")) 
```

## Denisty Plot: d ii. density plot

```{r}
ggplot(kgw_geosub, aes(no3_n, fill = geology)) + 
  geom_density(alpha = 0.3) + 
  theme_cowplot() + 
  xlab(bquote(NO[3]^" -")) + 
  ylab("Density")

```

## Evaluation of Statistical Tests: a. operations involving expanding, reorganizing, reshaping a data frame

Below is making a stats dataframe form the `kgw_chem` numeric data frame
```{r warning = FALSE}
# start data frame with column of means
stat_kgw <- data.frame(colMeans(kgw_chem,na.rm=TRUE))

# rename column
stat_kgw <- stat_kgw %>% 
  rename(mean = names(stat_kgw))

# add median
stat_kgw$median<-sapply(kgw_chem, function(med)  meds = median(med,na.rm=TRUE))

# add standard deviations
stat_kgw$sd<-sapply(kgw_chem, function(std)  sds = sd(std,na.rm=TRUE))

# add variance
stat_kgw$var<-sapply(kgw_chem, function(vr)  vars = var(vr,na.rm=TRUE))

# transpose such that stats are row names and analytes are cols
stat_kgw_mx <- as.matrix(stat_kgw)
stat_kgw_mx <- t(stat_kgw_mx)
stat_kgw <- as.data.frame(stat_kgw_mx)

stat_kgw
```
We can draw a few basic conclusions from the stats we have just generated. One is that for all analytes except ba, the median values are smaller than the mean values. This indicates a right skewed or positive skewed distribution. This is very common with environmental data, and water quality data in particular. Below I'll start explicitly evaluating the data distribution, starting with Shapiro-Wilkes. But before that I want to generate histograms to visually evaluate distributions.

## Histograms: d vi. barchart

```{r warning = FALSE}
# Before Shapiro-Wikes, I want to generate histograms for all analytes
par(mfrow=c(3,4))

for(i in 1:ncol(kgw_chem_subset)) {

  hist(unlist(kgw_chem_subset[,i]), na.rm = TRUE, main = "", xlab=colnames(kgw_chem_subset[i]))

}
```

## Shapiro-Wilkes: c ii

Looking at the histograms above, it appears that temperature looks the most normal, while ammonia looks least normal. I will use Shapiro-Wilkes on both of these distributions to test this hypothesis. For this test, if the p value is greater than the chosen alpha level, then the data are normally distributed. 
```{r warning = FALSE}
rm(stat_kgw_mx)

# Loop for w statistic and p-value from Shapiro-Wilkes
stat_kgw[nrow(stat_kgw) + 2, ] <- NA
rownames(stat_kgw)[rownames(stat_kgw) == "5"] = "shapiro_w"
rownames(stat_kgw)[rownames(stat_kgw) == "6"] = "shapiro_p"

for(i in 1:ncol(stat_kgw)){
  
  a <- unlist(kgw_chem[, i])
  st <- shapiro.test(a)
  w_stat <- st[1]
  p_val <- st[2]
  stat_kgw[5, i] <- w_stat
  stat_kgw[6, i] <- p_val
  
}

head(stat_kgw)
```
Contrary to my hypothesis, It appears that NONE of the analytes have a Shapiro p value above 0.05, and thus none are normaly distributed according to this test

## Kolmogorov-Smirnov Test: c v.

Now I want to check normality again using the K-S test. I am interested to see if the results of this test are different from Shapiro-Wilkes. For the K-S test, if the p value is greater than the chosen alpha level, then the data are normally distributed (the same as Shaprio-Wilkes).
```{r warning = FALSE}
stat_kgw[nrow(stat_kgw) + 2, ] <- NA
rownames(stat_kgw)[rownames(stat_kgw) == "7"] = "ks_d"
rownames(stat_kgw)[rownames(stat_kgw) == "8"] = "ks_p"

# Loop to test all cols
for(i in 1:ncol(stat_kgw)){
  
  stat_kgw_unl <- as.matrix(as.numeric(stat_kgw[, i])) 
  mean_kgw<-colMeans(kgw_chem[i], na.rm=T)
  sd_kgw <- sd(unlist(kgw_chem[i]), na.rm=T)
 kgw_ks <- ks.test(stat_kgw_unl, "pnorm", mean=mean_kgw, sd=sd_kgw)
  d_stat <- round(as.numeric(kgw_ks[1]), 4)
  p_value <- round(as.numeric(kgw_ks[2]), 4)
  stat_kgw[7, i] <- d_stat
  stat_kgw[8, i] <- p_value
  
}
```

Remarkably, results of the K-S test contrast quite strongly with Shapiro. According to K-S, all analytes show a normal distribution except Cl, pH, and Si.

## Kolmogorov-Smirnov Test for Log-normal Distribution: c v.
Because a lot of histograms and density curves appear to follow a log-normal distribution (as many hydrologic and environmental data sets do), I would like to perform the K-S test again, but testing for a log-normal distribution, to see if those analytes 
that didn't show a normal distribution end up showing a log-normal distribution. 

```{r warning = FALSE}

stat_kgw[nrow(stat_kgw) + 2, ] <- NA
rownames(stat_kgw)[rownames(stat_kgw) == "9"] = "ks_d_log"
rownames(stat_kgw)[rownames(stat_kgw) == "10"] = "ks_p_log"

# Loop to test all cols
for(i in 1:ncol(stat_kgw)){
  
  stat_kgw_unl <- as.matrix(as.numeric(stat_kgw[,i])) #as.matrix unlists the column
  mean_kgw<-colMeans(kgw_chem[i],na.rm=T)
  sd_kgw<-sd(unlist(kgw_chem[i]),na.rm=T)
 kgw_ks<-ks.test(stat_kgw_unl,"plnorm",mean=mean_kgw,sd=sd_kgw)
  d_stat_log<-round(as.numeric(kgw_ks[1]),4)
  p_value_log<-round(as.numeric(kgw_ks[2]),4)
  stat_kgw[9,i] <- d_stat_log
  stat_kgw[10,i] <- p_value_log
  
}
```

The p-values for the log-normal K-S test are all at 0, indicating that none of these distributions are log-normally distributed. So it turns out that Cl, pH, and Si have neither a normal distribution or a log-normal distribution. 

## QQ Plots: d i. QQ plot with interpretation supported by statistical tests

Since we now know that most of the analytes in this data set are indeed normally distributed, we can back up that 
interpretation by creating QQ plots for a subset of analytes. 

```{r warning = FALSE}
par(new = TRUE)
par(mfrow=c(3,4))

names(kgw_chem_subset)

qqnorm(kgw_chem_subset$na1, main = "na1")
qqnorm(kgw_chem_subset$na2, main = "na2")
qqnorm(kgw_chem_subset$ca1, main = "ca1")
qqnorm(kgw_chem_subset$nh4_n, main = "nh4_n")
qqnorm(kgw_chem_subset$no3_n, main = "no3_n")
qqnorm(kgw_chem_subset$alkalinity, main = "alkalinity")
qqnorm(kgw_chem_subset$temp, main = "temp")
qqnorm(kgw_chem_subset$mg1, main = "mg1")
qqnorm(kgw_chem_subset$cl, main = "cl")
qqnorm(kgw_chem_subset$so4, main = "so4")
qqnorm(kgw_chem_subset$k1, main = "k1")


```

This result is interesting to me, because a lot of these don't appear as very straight lines, although most are somewhat straight. This to me reinforces the fact that Shapiro identified almost no normal distributions, while K-S identified most analytes as normal.

## Identifying Outliers: Rosner Test: c iv.
Moving on from tests for normality, I want to use the Rosner test to identify potential outliers, and see generally tracks with the appearance of the nitrate boxplots 

```{r warning = FALSE}

# Rosner test for Nitrate
ros <- rosnerTest(unlist(kgw_chem[, 16]), k=15)

ros$n.outliers

ros$all.stats
```

According to Rosner, there are 15 outliers, all occurring on the high end. This matches my intuition based on the boxplot generated earlier. 

## PCA of Full Konza GW Chem 

```{r}




```

Now we will revisit the relationship between mg1 and cl...

## Linear model for correlated vars: g. bet fit linear model

```{r}
linearmod<-lm(kgw_chem_subset$mg1 ~ kgw_chem_subset$cl) #perform the regression
sumlinearmod<-summary(linearmod) #write summary of regression
sumlinearmod
m<-round(linearmod$coefficients[2],3) #take slope from summary report
intcpt<-round(linearmod$coefficients[1],3) #take intercept
r2<-round(sumlinearmod$r.squared,3) #take r squared

tx1<-as.expression(bquote("r"^2 ~ "=" ~ .(r2)))
tx2<-c(paste("m = ",m,"\n"),
paste("b = ",intcpt,"\n"),
tx1)

plot(mg1 ~ cl, data = kgw_chem_subset, main="Linear Model")
abline(lm(kgw_chem_subset$mg1 ~ kgw_chem_subset$cl, data = kgw_chem_subset), col = "red")
legend("topright", inset=0.03,tx2,box.lty = 0)

```

## Examination of storage, and surface flow duration
In my research I want to examine surface water - groundwater interactions at konza (which has an intermittent stream system). To do this, I want to find variables that correlate with flow duration at each location where we have placed a Stream Temperature, Intermittency, and Conductivty (STIC) logger. Below is a map of flow duration for each logger form the period June 2021 to September 2021. Before I can generate this map, I need to combine, tidy, and my classify my data which includes the use of a map function, as well as conditional branching. 

## Preparing Flow Duration metrics: map function and conditional statement
```{r, include = FALSE, warning = FALSE}
data_dir <- "processed_stic_names"

fs::dir_ls(data_dir)

length(data_dir)

stic_files <- fs::dir_ls(data_dir, regexp = "\\.csv$")

stic_files <- stic_files %>% 
  map_dfr(read_csv)

stic_files <- stic_files %>% 
  dplyr::mutate(wetdry = if_else(conductivity >= 1000, "wet", "dry" ))

stic_files <- stic_files %>% 
  mutate(date = lubridate::date(datetime))

stic_files <- stic_files %>% 
  dplyr::filter(datetime >= "2021-05-23")

stic_files <- stic_files %>% 
  mutate(day = lubridate::yday(date))

### Calculate flow duration for each sensor
stic_duration <- stic_files %>% 
  group_by(logger) %>% 
  summarise(n_wet = sum(wetdry == "wet", na.rm = TRUE), count = n()) %>% 
  mutate(duration = n_wet/count)

head(stic_duration)
```

Now I can make a map of the logger locations, colored by the flow duration for each logger (proportion of total 15-min observations that are classified as wet, out of the total number of observations).

## Flow Duration Map: a. operations involving expanding, reorganizing, reshaping a data frame

```{r warning = FALSE}
Konza_STICData_highlight <- read_excel("Konza_STICData_highlight.xlsx", 
                                       sheet = "Konza_AllSTICs")

Konza_STICData_highlight <- Konza_STICData_highlight %>% 
  rename(logger = STIC)


Konza_STICData_highlight$logger <- as.numeric(Konza_STICData_highlight$logger)


konza_high_stic_coord <- left_join(Konza_STICData_highlight, stic_duration, by = "logger", na.rm = TRUE)


konza_duration_map <- konza_high_stic_coord %>% 
  dplyr::select(logger, duration, lat, long)


konza_duration_map <- konza_duration_map %>% 
  drop_na(logger, duration, lat, long)

konza_map <- st_as_sf(konza_duration_map, coords = c("long", "lat"), crs = 4326)

head(konza_map)

# now generate final map
ggplot() + 
  geom_sf(data = konza_streams) + 
  geom_sf(data = konza_map, aes(color = duration), size = 3) +
  scale_color_viridis_c(direction = -1) +
  theme_classic() +
  ggtitle("Konza STIC Durations") + 
  xlab("Longitude") + 
  ylab("Latitude") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  coord_sf(xlim = c(708000.9  , 710500.3 ), ylim = c(4327200.8  , 4330000.0 ), expand = FALSE) +
  theme(axis.text=element_text(size=10), axis.title=element_text(size=15)) + 
  theme(plot.title = element_text(size=18)) + 
  xlab("Longitude") + 
  ylab("Latitude")

```
One of the major findings from examining this map is that watersheds at Konza do not dry from top to bottom. Especially in N04D, many sites in the middle of the watershed exhibit the longest flow duration. My working hypothesis is that groundwater seeps and springs (many of which are located in the middle of N04D) are responsible for this flow persistence. 

## Correlations between flow duration and other physiographic metrics: xy plot and statistical significance 

Now I want to look at how these flow duration values by logger compare with physiographic metrics derived from DEM for the drainage areas of each logger.

```{r warning = FALSE}

# Bring in physiographic metrics csv
konza_phys <- read_csv("Konza_AllSTICsWithDetails.csv")

# Bring in an index sheet to match site name wth serial number
stic_name_SN <- read_csv("STIC_name_SN.csv") %>% 
  rename(logger = STIC_SN)

# join above two data frames
stic_duration_sn <- left_join(stic_name_SN, stic_duration, by = "logger")

# join by site name to create physiographic metrics data frame
konza_metrics <- left_join(stic_duration_sn, konza_phys, by = "STIC_name")

head(konza_metrics)

par(mfrow=c(2,2))

plot(konza_metrics$TWI, konza_metrics$duration)
plot(konza_metrics$ContributingArea_ha, konza_metrics$duration)
plot(konza_metrics$Elevation_m, konza_metrics$duration)
plot(konza_metrics$Slope_prc, konza_metrics$duration)
```
As it turns out, none of these four metrics appear to have any correlation with flow duration. This is highly unexpected. At least for TWI, you would expect there would be a strong positive correlation between this and flow duration.

Just to be sure, I am going to perform linear correlations to look at the p values.

## Investigating significance of linear relationships 
```{r}

twi_lm <- lm(konza_metrics$duration ~ konza_metrics$TWI)
drainage_lm <- lm(konza_metrics$duration ~ konza_metrics$ContributingArea_ha)
elevation_lm <- lm(konza_metrics$duration ~ konza_metrics$Elevation_m)
slope_lm <- lm(konza_metrics$duration ~ konza_metrics$Slope_prc)

summary(twi_lm)
summary(drainage_lm)
summary(elevation_lm)
summary(slope_lm)

```

As we can see, none of these linear models show significant p-values (as well as extremely low r-squared values). So we know that these metrics are not predictors of surface flow duration at Konza. Going forward, I want to find more variables to test for correlations (including the unit outcropping at each site)

## Relationship between soil storage and wet network proportion 

Finally, I want to shed some light on how soil storage relates to surface flow in this system. For this I will use additional existing Konza data (storage in the upper 50 cm of soil). However, these stations only began collecting data in July of 2021.

### Map of Average Soil Water Storage at Konza
```{r warning = FALSE}
# bring in data from all stations and  row bind

station_1 <- read_csv("pulse_data/s_1.csv")
station_2 <- read_csv("pulse_data/s_2.csv")
station_3 <- read_csv("pulse_data/s_3.csv")
station_4 <- read_csv("pulse_data/s_4.csv")
station_5 <- read_csv("pulse_data/s_5.csv")
station_6 <- read_csv("pulse_data/s_6.csv")
station_7 <- read_csv("pulse_data/s_7.csv")
station_8 <- read_csv("pulse_data/s_8.csv")
station_9 <- read_csv("pulse_data/s_9.csv")
station_10 <- read_csv("pulse_data/s_10.csv")
station_11 <- read_csv("pulse_data/s_11.csv")
station_12 <- read_csv("pulse_data/s_12.csv")
station_13 <- read_csv("pulse_data/s_13.csv")
station_14 <- read_csv("pulse_data/s_14.csv")
station_15 <- read_csv("pulse_data/s_15.csv")
station_16 <- read_csv("pulse_data/s_16.csv")

station_1$id <- "01"
station_2$id <- "02"
station_3$id <- "03"
station_4$id <- "04"
station_5$id <- "05"
station_6$id <- "06"
station_7$id <- "07"
station_8$id <- "08"
station_9$id <- "09"
station_10$id <- "10"
station_11$id <- "11"
station_12$id <- "12"
station_13$id <- "13"
station_14$id <- "14"
station_15$id <- "15"
station_16$id <- "16"

k_p <- bind_rows(station_1, station_2, station_3, station_4, station_5, station_6, 
                 station_7, station_8, station_9, station_10, station_11, station_12,
                 station_13, station_14, station_15, station_16)


# clean up the data frame

k_p <- k_p %>% 
  dplyr::mutate(datetime = lubridate::ymd_hms(datetime)) %>% 
  janitor::clean_names() %>% 
  dplyr::select(- x1) %>% 
  dplyr::mutate(id = as.numeric(id))

# bring in coords

pulse_coords <- read_csv("pulse_coords.csv", 
                         col_types = cols(id = col_number()))


pulse_map <- dplyr::left_join(pulse_coords, k_p, by = "id")

### Make Duration Map


pulse_locs <- st_as_sf(pulse_map,coords = c("long", "lat"), crs = 4326)

mean_kp <- pulse_locs %>% 
  group_by(id) %>% 
  summarize(storage_50cm = mean(storage_50_cm, na.rm = TRUE))

ggplot() + 
  geom_sf(data = konza_boundary) +
  geom_sf(data = konza_streams) + 
  geom_sf(data = mean_kp, size = 4, aes(color = storage_50cm)) +
  scale_color_viridis_c(direction = -1, name = "mean storage 50 cm") +
  theme_cowplot() +
  xlab("Longitude") + 
  ylab("Latitude") + 
  xlab("Longitude") + 
  ylab("Latitude") + 
  ggtitle("Konza Pulse (July 2021 - April 2022)") + 
  theme(plot.title = element_text(hjust = 0.5))

```

## Relationship between soil storage and wet network proportion

